{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : search-EXP-20200710-181910\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model_search import Network\n",
    "from architect import Architect\n",
    "\n",
    "import genotypes\n",
    "\n",
    "import copy\n",
    "from default_option import TrainOptions\n",
    "\n",
    "parser = argparse.ArgumentParser(\"cifar\")\n",
    "parser.add_argument('--data', type=str, default='../data', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.025, help='init learning rate')\n",
    "parser.add_argument('--learning_rate_min', type=float, default=0.001, help='min learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-3, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=50, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=16, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=8, help='total number of layers')\n",
    "parser.add_argument('--model_path', type=str, default='saved_models', help='path to save the model')\n",
    "parser.add_argument('--cutout', action='store_true', default=False, help='use cutout')\n",
    "parser.add_argument('--cutout_length', type=int, default=16, help='cutout length')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0.3, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='EXP', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=100, help='random seed')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "parser.add_argument('--train_portion', type=float, default=0.5, help='portion of training data')\n",
    "parser.add_argument('--unrolled', action='store_true', default=f, help='use one-step unrolled validation loss')\n",
    "parser.add_argument('--arch_learning_rate', type=float, default=3e-4, help='learning rate for arch encoding')\n",
    "parser.add_argument('--arch_weight_decay', type=float, default=1e-3, help='weight decay for arch encoding')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.save = 'search-{}-{}'.format(args.save, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "\n",
    "log_format = '%(asctime)s %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "CIFAR_CLASSES = 10\n",
    "\n",
    "def train(train_queue, valid_queue, model, architect, criterion, optimizer, lr):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    for step, (input, target) in enumerate(train_queue):\n",
    "        model.train()\n",
    "        n = input.size(0)\n",
    "        input = Variable(input, requires_grad=False).cuda()\n",
    "        target = Variable(target, requires_grad=False).cuda(async=True)\n",
    "        # get a random minibatch from the search queue with replacement\n",
    "        input_search, target_search = next(iter(valid_queue))\n",
    "        input_search = Variable(input_search, requires_grad=False).cuda()\n",
    "        target_search = Variable(target_search, requires_grad=False).cuda(async=True)\n",
    "        architect.step(input, target, input_search, target_search, lr, optimizer, unrolled=args.unrolled)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input)\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1.data, n)\n",
    "        top5.update(prec5.data, n)\n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "    return top1.avg, objs.avg\n",
    "\n",
    "\n",
    "def infer(valid_queue, model, criterion):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    model.eval()\n",
    "    for step, (input, target) in enumerate(valid_queue):\n",
    "        input = Variable(input, volatile=True).cuda()\n",
    "        target = Variable(target, volatile=True).cuda(async=True)\n",
    "        logits = model(input)\n",
    "        loss = criterion(logits, target)\n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1.data, n)\n",
    "        top5.update(prec5.data, n)\n",
    "\n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "    return top1.avg, objs.avg\n",
    "\n",
    "def random_arch_generate():\n",
    "    num_ops = len(genotypes.PRIMITIVES)\n",
    "    n_nodes = 4####model._step\n",
    "\n",
    "    arch_gene = []\n",
    "    for i in range(n_nodes):\n",
    "        ops = np.random.choice(range(num_ops), 2)\n",
    "        nodes_in_normal = np.random.choice(range(i+2), 2)##############################modify\n",
    "        arch_gene.extend([(ops[0],nodes_in_normal[0]), (ops[1],nodes_in_normal[1])])\n",
    "    return arch_gene  \n",
    "\n",
    "def get_weights_from_arch(arch_comb):\n",
    "    k = sum(1 for i in range(model._steps) for n in range(2+i))\n",
    "    num_ops = len(genotypes.PRIMITIVES)\n",
    "    n_nodes = model._steps\n",
    "\n",
    "    alphas_normal = Variable(torch.zeros(k, num_ops).cuda(), requires_grad=False)\n",
    "    alphas_reduce = Variable(torch.zeros(k, num_ops).cuda(), requires_grad=False)\n",
    "\n",
    "    offset = 0\n",
    "    for i in range(n_nodes):\n",
    "        normal1 = np.int_(arch_comb[0][2*i])\n",
    "        normal2 = np.int_(arch_comb[0][2*i+1])\n",
    "        reduce1 = np.int_(arch_comb[1][2*i])\n",
    "        reduce2 = np.int_(arch_comb[1][2*i+1])\n",
    "        alphas_normal[offset+normal1[1],normal1[0]] = 1\n",
    "        alphas_normal[offset+normal2[1],normal2[0]] = 1\n",
    "        alphas_reduce[offset+reduce1[1],reduce1[0]] = 1\n",
    "        alphas_reduce[offset+reduce2[1],reduce2[0]] = 1\n",
    "        offset += (i+2)\n",
    "\n",
    "    model_weights = [\n",
    "      alphas_normal,\n",
    "      alphas_reduce,\n",
    "    ]\n",
    "    return model_weights\n",
    "\n",
    "def set_model_weights(model, weights):\n",
    "    model.alphas_normal = weights[0]\n",
    "    model.alphas_reduce = weights[1]\n",
    "    model._arch_parameters = [model.alphas_normal, model.alphas_reduce]\n",
    "    return model\n",
    "\n",
    "def infer_val(valid_queue, model,arch_gen_compa, criterion):\n",
    "    \n",
    "    arch_param_save=model.arch_parameters()\n",
    "    model_weights=get_weights_from_arch(arch_gen_compa)        ###########################\n",
    "    model_save=set_model_weights(model,model_weights)#############\n",
    "   \n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    model_save.eval() \n",
    "\n",
    "    for step, (input, target) in enumerate(valid_queue):\n",
    "        input = Variable(input, volatile=True).cuda()\n",
    "        target = Variable(target, volatile=True).cuda(async=True)\n",
    "\n",
    "        logits = model_save(input)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1.data, n)\n",
    "        top5.update(prec5.data, n)\n",
    "\n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "    model=set_model_weights(model,arch_param_save)###########################set back\n",
    "    return top1.avg, objs.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:19:10 PM gpu device = 1\n",
      "07/10 06:19:10 PM args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=32, cutout=False, cutout_length=16, data='../data', drop_path_prob=0.3, epochs=50, gpu=1, grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, report_freq=50, save='search-EXP-20200710-181910', seed=100, train_portion=0.5, unrolled=True, weight_decay=0.003)\n",
      "07/10 06:19:13 PM param size = 1.930618MB\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "07/10 06:19:15 PM epoch 0 lr 2.495266e-02\n",
      "07/10 06:19:15 PM genotype = Genotype(normal=[('avg_pool_3x3', 0), ('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('dil_conv_3x3', 2), ('avg_pool_3x3', 0), ('avg_pool_3x3', 2), ('sep_conv_3x3', 4), ('sep_conv_5x5', 2)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1), ('dil_conv_5x5', 0), ('avg_pool_3x3', 0), ('dil_conv_5x5', 1), ('skip_connect', 3), ('avg_pool_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_3x3', 4)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1248, 0.1251, 0.1251, 0.1249, 0.1251, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251],\n",
      "        [0.1249, 0.1248, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251],\n",
      "        [0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249, 0.1252],\n",
      "        [0.1251, 0.1249, 0.1249, 0.1251, 0.1251, 0.1249, 0.1252, 0.1248],\n",
      "        [0.1248, 0.1250, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1252],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1251, 0.1252, 0.1249, 0.1250, 0.1249, 0.1249, 0.1251],\n",
      "        [0.1249, 0.1252, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1253, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249, 0.1251, 0.1249],\n",
      "        [0.1252, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250],\n",
      "        [0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1250, 0.1250],\n",
      "        [0.1252, 0.1248, 0.1249, 0.1251, 0.1249, 0.1251, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1252, 0.1250, 0.1250, 0.1249]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1248, 0.1251, 0.1251],\n",
      "        [0.1248, 0.1251, 0.1252, 0.1250, 0.1252, 0.1250, 0.1249, 0.1248],\n",
      "        [0.1252, 0.1249, 0.1252, 0.1248, 0.1251, 0.1251, 0.1250, 0.1247],\n",
      "        [0.1249, 0.1249, 0.1250, 0.1251, 0.1251, 0.1248, 0.1251, 0.1252],\n",
      "        [0.1252, 0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1248, 0.1251],\n",
      "        [0.1253, 0.1249, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1251, 0.1248, 0.1251, 0.1248, 0.1251],\n",
      "        [0.1249, 0.1250, 0.1250, 0.1253, 0.1250, 0.1249, 0.1251, 0.1248],\n",
      "        [0.1252, 0.1250, 0.1249, 0.1249, 0.1254, 0.1247, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1249, 0.1251],\n",
      "        [0.1249, 0.1249, 0.1248, 0.1252, 0.1252, 0.1249, 0.1252, 0.1250],\n",
      "        [0.1249, 0.1250, 0.1252, 0.1251, 0.1248, 0.1251, 0.1249, 0.1250],\n",
      "        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1251, 0.1249]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:19:21 PM train 000 2.239793e+00 15.625000 68.750000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:23:45 PM train 050 2.164941e+00 23.529413 73.039215\n",
      "07/10 06:28:03 PM train 100 2.041115e+00 25.959158 77.413368\n",
      "07/10 06:32:26 PM train 150 1.972051e+00 27.649006 79.925499\n",
      "07/10 06:32:57 PM train_acc 27.980000\n",
      "07/10 06:32:57 PM valid 000 1.920506e+00 25.000000 87.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/ipykernel_launcher.py:99: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/ipykernel_launcher.py:100: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:33:06 PM valid 050 1.877861e+00 31.372551 85.723045\n",
      "07/10 06:33:14 PM valid 100 1.862454e+00 32.518562 85.581680\n",
      "07/10 06:33:22 PM valid 150 1.874344e+00 32.243378 85.326988\n",
      "07/10 06:33:23 PM valid_acc 27.980000\n",
      "07/10 06:33:24 PM valid 000 1.964596e+00 18.750000 84.375000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/ipykernel_launcher.py:169: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/data/yanhzhan/anaconda_y/lib/python3.6/site-packages/ipykernel_launcher.py:170: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:33:31 PM valid 050 1.929882e+00 28.370098 82.230392\n",
      "07/10 06:33:39 PM valid 100 1.924605e+00 28.186880 81.961632\n",
      "07/10 06:33:47 PM valid 150 1.926490e+00 28.166391 81.332779\n",
      "07/10 06:33:48 PM valid_acc1 28.199999\n",
      "07/10 06:33:48 PM valid 000 2.289657e+00 18.750000 84.375000\n",
      "07/10 06:33:56 PM valid 050 2.032436e+00 29.840687 83.639709\n",
      "07/10 06:34:04 PM valid 100 2.036143e+00 30.352722 84.003708\n",
      "07/10 06:34:12 PM valid 150 2.029311e+00 30.070364 83.795532\n",
      "07/10 06:34:13 PM valid_acc2 30.379999\n",
      "07/10 06:34:13 PM valid 000 1.900132e+00 31.250000 87.500000\n",
      "07/10 06:34:21 PM valid 050 2.001703e+00 30.024511 84.803925\n",
      "07/10 06:34:29 PM valid 100 2.010486e+00 29.486385 83.879951\n",
      "07/10 06:34:37 PM valid 150 2.011057e+00 29.573675 83.981789\n",
      "07/10 06:34:38 PM valid_acc3 29.500000\n",
      "07/10 06:34:38 PM valid 000 1.704269e+00 28.125000 87.500000\n",
      "07/10 06:34:46 PM valid 050 1.985026e+00 28.308825 78.615196\n",
      "07/10 06:34:54 PM valid 100 1.997343e+00 27.382425 78.743813\n",
      "07/10 06:35:02 PM valid 150 1.988654e+00 27.980133 78.849335\n",
      "07/10 06:35:03 PM valid_acc4 27.900000\n",
      "07/10 06:35:03 PM epoch 1 lr 2.483464e-02\n",
      "07/10 06:35:03 PM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2), ('dil_conv_3x3', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 0), ('sep_conv_3x3', 2), ('dil_conv_3x3', 4)], normal_concat=range(2, 6), reduce=[('sep_conv_3x3', 1), ('max_pool_3x3', 0), ('max_pool_3x3', 1), ('sep_conv_5x5', 0), ('dil_conv_3x3', 0), ('sep_conv_5x5', 2), ('skip_connect', 2), ('skip_connect', 3)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1247, 0.1252, 0.1237, 0.1244, 0.1255, 0.1256, 0.1264, 0.1245],\n",
      "        [0.1264, 0.1246, 0.1241, 0.1246, 0.1250, 0.1252, 0.1250, 0.1250],\n",
      "        [0.1252, 0.1251, 0.1238, 0.1247, 0.1244, 0.1253, 0.1259, 0.1256],\n",
      "        [0.1258, 0.1246, 0.1237, 0.1244, 0.1248, 0.1258, 0.1250, 0.1259],\n",
      "        [0.1270, 0.1232, 0.1221, 0.1244, 0.1256, 0.1257, 0.1259, 0.1260],\n",
      "        [0.1260, 0.1247, 0.1234, 0.1237, 0.1255, 0.1263, 0.1252, 0.1253],\n",
      "        [0.1264, 0.1241, 0.1237, 0.1241, 0.1255, 0.1258, 0.1248, 0.1256],\n",
      "        [0.1276, 0.1230, 0.1224, 0.1235, 0.1266, 0.1256, 0.1258, 0.1254],\n",
      "        [0.1281, 0.1231, 0.1221, 0.1236, 0.1260, 0.1258, 0.1255, 0.1257],\n",
      "        [0.1259, 0.1248, 0.1234, 0.1241, 0.1259, 0.1255, 0.1253, 0.1251],\n",
      "        [0.1265, 0.1241, 0.1235, 0.1241, 0.1249, 0.1257, 0.1257, 0.1254],\n",
      "        [0.1270, 0.1230, 0.1226, 0.1240, 0.1265, 0.1255, 0.1260, 0.1255],\n",
      "        [0.1277, 0.1229, 0.1222, 0.1237, 0.1262, 0.1261, 0.1255, 0.1258],\n",
      "        [0.1273, 0.1231, 0.1224, 0.1230, 0.1259, 0.1260, 0.1263, 0.1259]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1250, 0.1257, 0.1252, 0.1248, 0.1244, 0.1245, 0.1249, 0.1254],\n",
      "        [0.1247, 0.1254, 0.1249, 0.1253, 0.1257, 0.1247, 0.1248, 0.1243],\n",
      "        [0.1246, 0.1251, 0.1249, 0.1251, 0.1245, 0.1257, 0.1250, 0.1251],\n",
      "        [0.1248, 0.1258, 0.1255, 0.1249, 0.1244, 0.1243, 0.1250, 0.1253],\n",
      "        [0.1257, 0.1244, 0.1240, 0.1253, 0.1256, 0.1252, 0.1250, 0.1248],\n",
      "        [0.1248, 0.1252, 0.1248, 0.1243, 0.1246, 0.1256, 0.1260, 0.1247],\n",
      "        [0.1243, 0.1255, 0.1252, 0.1247, 0.1253, 0.1252, 0.1246, 0.1252],\n",
      "        [0.1250, 0.1247, 0.1243, 0.1253, 0.1251, 0.1257, 0.1246, 0.1253],\n",
      "        [0.1252, 0.1246, 0.1245, 0.1256, 0.1248, 0.1252, 0.1253, 0.1248],\n",
      "        [0.1249, 0.1257, 0.1254, 0.1250, 0.1253, 0.1247, 0.1239, 0.1251],\n",
      "        [0.1247, 0.1254, 0.1253, 0.1248, 0.1252, 0.1248, 0.1249, 0.1250],\n",
      "        [0.1256, 0.1244, 0.1243, 0.1260, 0.1250, 0.1248, 0.1250, 0.1249],\n",
      "        [0.1254, 0.1243, 0.1249, 0.1258, 0.1242, 0.1247, 0.1252, 0.1253],\n",
      "        [0.1250, 0.1248, 0.1250, 0.1258, 0.1252, 0.1242, 0.1250, 0.1251]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "07/10 06:35:09 PM train 000 1.991291e+00 25.000000 81.250000\n",
      "07/10 06:39:34 PM train 050 1.783256e+00 34.436275 85.723045\n",
      "07/10 06:43:55 PM train 100 1.745068e+00 35.272278 86.788368\n",
      "07/10 06:48:24 PM train 150 1.717351e+00 35.968544 87.727646\n",
      "07/10 06:48:55 PM train_acc 36.160000\n",
      "07/10 06:48:56 PM valid 000 1.829534e+00 46.875000 81.250000\n",
      "07/10 06:49:04 PM valid 050 1.648625e+00 37.745098 89.705887\n",
      "07/10 06:49:12 PM valid 100 1.682136e+00 37.438118 88.582916\n",
      "07/10 06:49:20 PM valid 150 1.684558e+00 37.148178 88.576157\n",
      "07/10 06:49:21 PM valid_acc 36.160000\n",
      "07/10 06:49:21 PM valid 000 1.655462e+00 34.375000 96.875000\n",
      "07/10 06:49:29 PM valid 050 1.824620e+00 30.821079 84.620102\n",
      "07/10 06:49:37 PM valid 100 1.824991e+00 30.043316 84.777229\n",
      "07/10 06:49:45 PM valid 150 1.810922e+00 30.567053 85.016556\n",
      "07/10 06:49:46 PM valid_acc1 30.539999\n",
      "07/10 06:49:46 PM valid 000 1.869815e+00 31.250000 93.750000\n",
      "07/10 06:49:54 PM valid 050 1.807737e+00 35.784313 87.193634\n",
      "07/10 06:50:01 PM valid 100 1.801151e+00 37.159653 87.407173\n",
      "07/10 06:50:09 PM valid 150 1.797906e+00 36.568710 87.603477\n",
      "07/10 06:50:10 PM valid_acc2 36.500000\n",
      "07/10 06:50:11 PM valid 000 1.614940e+00 31.250000 90.625000\n",
      "07/10 06:50:18 PM valid 050 1.725798e+00 36.703434 88.174026\n",
      "07/10 06:50:26 PM valid 100 1.735256e+00 35.983910 87.592819\n",
      "07/10 06:50:34 PM valid 150 1.720710e+00 36.196194 87.810432\n",
      "07/10 06:50:35 PM valid_acc3 36.160000\n",
      "07/10 06:50:35 PM valid 000 1.548947e+00 56.250000 90.625000\n",
      "07/10 06:50:43 PM valid 050 1.650553e+00 36.948532 87.867653\n",
      "07/10 06:50:51 PM valid 100 1.654857e+00 36.757423 88.366333\n",
      "07/10 06:51:00 PM valid 150 1.656931e+00 37.148178 88.658943\n",
      "07/10 06:51:01 PM valid_acc4 37.180000\n",
      "07/10 06:51:01 PM epoch 2 lr 2.467010e-02\n",
      "07/10 06:51:01 PM genotype = Genotype(normal=[('max_pool_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 1), ('max_pool_3x3', 0), ('dil_conv_5x5', 3), ('sep_conv_3x3', 2), ('sep_conv_3x3', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('max_pool_3x3', 1), ('sep_conv_5x5', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 2), ('dil_conv_3x3', 0), ('sep_conv_3x3', 0), ('dil_conv_5x5', 3)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1237, 0.1268, 0.1230, 0.1244, 0.1258, 0.1257, 0.1263, 0.1244],\n",
      "        [0.1284, 0.1242, 0.1224, 0.1235, 0.1250, 0.1256, 0.1256, 0.1255],\n",
      "        [0.1244, 0.1267, 0.1231, 0.1247, 0.1239, 0.1253, 0.1266, 0.1253],\n",
      "        [0.1275, 0.1239, 0.1217, 0.1230, 0.1244, 0.1260, 0.1265, 0.1270],\n",
      "        [0.1280, 0.1228, 0.1209, 0.1240, 0.1255, 0.1264, 0.1260, 0.1264],\n",
      "        [0.1257, 0.1259, 0.1223, 0.1233, 0.1247, 0.1267, 0.1260, 0.1253],\n",
      "        [0.1281, 0.1236, 0.1221, 0.1229, 0.1255, 0.1258, 0.1251, 0.1269],\n",
      "        [0.1282, 0.1224, 0.1209, 0.1223, 0.1270, 0.1269, 0.1262, 0.1261],\n",
      "        [0.1297, 0.1224, 0.1204, 0.1226, 0.1261, 0.1260, 0.1258, 0.1272],\n",
      "        [0.1252, 0.1264, 0.1229, 0.1241, 0.1254, 0.1262, 0.1248, 0.1250],\n",
      "        [0.1281, 0.1234, 0.1213, 0.1225, 0.1254, 0.1258, 0.1269, 0.1267],\n",
      "        [0.1280, 0.1223, 0.1209, 0.1230, 0.1274, 0.1256, 0.1266, 0.1262],\n",
      "        [0.1290, 0.1220, 0.1204, 0.1226, 0.1268, 0.1269, 0.1259, 0.1264],\n",
      "        [0.1283, 0.1220, 0.1208, 0.1219, 0.1266, 0.1270, 0.1265, 0.1268]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1255, 0.1263, 0.1246, 0.1247, 0.1241, 0.1245, 0.1248, 0.1256],\n",
      "        [0.1245, 0.1261, 0.1247, 0.1249, 0.1258, 0.1244, 0.1256, 0.1240],\n",
      "        [0.1245, 0.1253, 0.1239, 0.1248, 0.1251, 0.1264, 0.1246, 0.1254],\n",
      "        [0.1251, 0.1262, 0.1251, 0.1251, 0.1242, 0.1247, 0.1245, 0.1253],\n",
      "        [0.1259, 0.1246, 0.1226, 0.1246, 0.1262, 0.1256, 0.1254, 0.1252],\n",
      "        [0.1243, 0.1255, 0.1241, 0.1241, 0.1241, 0.1261, 0.1263, 0.1254],\n",
      "        [0.1240, 0.1258, 0.1249, 0.1247, 0.1256, 0.1251, 0.1243, 0.1256],\n",
      "        [0.1251, 0.1249, 0.1227, 0.1243, 0.1247, 0.1273, 0.1249, 0.1262],\n",
      "        [0.1245, 0.1252, 0.1235, 0.1251, 0.1253, 0.1260, 0.1252, 0.1251],\n",
      "        [0.1251, 0.1256, 0.1246, 0.1248, 0.1262, 0.1247, 0.1240, 0.1249],\n",
      "        [0.1247, 0.1255, 0.1251, 0.1248, 0.1247, 0.1252, 0.1249, 0.1251],\n",
      "        [0.1266, 0.1244, 0.1231, 0.1253, 0.1254, 0.1252, 0.1249, 0.1251],\n",
      "        [0.1254, 0.1247, 0.1238, 0.1248, 0.1243, 0.1259, 0.1252, 0.1260],\n",
      "        [0.1255, 0.1254, 0.1248, 0.1258, 0.1255, 0.1227, 0.1247, 0.1255]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "07/10 06:51:06 PM train 000 1.213446e+00 53.125000 93.750000\n",
      "07/10 06:55:26 PM train 050 1.634174e+00 38.725491 88.786766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 06:59:46 PM train 100 1.601608e+00 40.655941 89.944305\n",
      "07/10 07:04:08 PM train 150 1.596171e+00 41.245861 90.169701\n",
      "07/10 07:04:40 PM train_acc 41.520000\n",
      "07/10 07:04:41 PM valid 000 1.946936e+00 37.500000 84.375000\n",
      "07/10 07:04:49 PM valid 050 1.512204e+00 43.259804 92.034317\n",
      "07/10 07:04:57 PM valid 100 1.551858e+00 42.048267 91.491333\n",
      "07/10 07:05:05 PM valid 150 1.555942e+00 42.591061 91.452812\n",
      "07/10 07:05:06 PM valid_acc 41.520000\n",
      "07/10 07:05:06 PM valid 000 1.786620e+00 28.125000 87.500000\n",
      "07/10 07:05:14 PM valid 050 1.748761e+00 35.845589 86.764709\n",
      "07/10 07:05:22 PM valid 100 1.757464e+00 35.210396 86.571777\n",
      "07/10 07:05:30 PM valid 150 1.752637e+00 35.347683 86.713577\n",
      "07/10 07:05:31 PM valid_acc1 35.160000\n",
      "07/10 07:05:31 PM valid 000 1.789545e+00 37.500000 90.625000\n",
      "07/10 07:05:39 PM valid 050 1.523920e+00 45.098042 91.789223\n",
      "07/10 07:05:47 PM valid 100 1.547313e+00 43.966583 91.522278\n",
      "07/10 07:05:55 PM valid 150 1.535993e+00 44.391556 91.370033\n",
      "07/10 07:05:56 PM valid_acc2 44.480000\n",
      "07/10 07:05:56 PM valid 000 1.849840e+00 31.250000 93.750000\n",
      "07/10 07:06:04 PM valid 050 1.540895e+00 44.546570 90.625000\n",
      "07/10 07:06:12 PM valid 100 1.562713e+00 43.409653 90.903465\n",
      "07/10 07:06:19 PM valid 150 1.560582e+00 43.129139 91.370033\n",
      "07/10 07:06:20 PM valid_acc3 43.279999\n",
      "07/10 07:06:21 PM valid 000 1.515072e+00 46.875000 93.750000\n",
      "07/10 07:06:29 PM valid 050 1.587739e+00 41.666668 91.482849\n",
      "07/10 07:06:39 PM valid 100 1.584490e+00 41.522278 91.150986\n",
      "07/10 07:06:47 PM valid 150 1.595187e+00 40.956127 90.521523\n",
      "07/10 07:06:48 PM valid_acc4 40.980000\n",
      "07/10 07:06:48 PM epoch 3 lr 2.445969e-02\n",
      "07/10 07:06:48 PM genotype = Genotype(normal=[('max_pool_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 1), ('max_pool_3x3', 0), ('dil_conv_5x5', 1), ('dil_conv_5x5', 3), ('sep_conv_3x3', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('max_pool_3x3', 1), ('max_pool_3x3', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 2), ('max_pool_3x3', 0), ('max_pool_3x3', 0), ('sep_conv_5x5', 3)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1231, 0.1284, 0.1219, 0.1244, 0.1260, 0.1256, 0.1261, 0.1245],\n",
      "        [0.1300, 0.1235, 0.1199, 0.1216, 0.1260, 0.1266, 0.1260, 0.1263],\n",
      "        [0.1239, 0.1283, 0.1220, 0.1245, 0.1237, 0.1253, 0.1273, 0.1250],\n",
      "        [0.1294, 0.1236, 0.1197, 0.1217, 0.1234, 0.1260, 0.1279, 0.1283],\n",
      "        [0.1285, 0.1231, 0.1195, 0.1235, 0.1253, 0.1265, 0.1263, 0.1273],\n",
      "        [0.1260, 0.1278, 0.1210, 0.1229, 0.1243, 0.1270, 0.1256, 0.1254],\n",
      "        [0.1303, 0.1230, 0.1197, 0.1210, 0.1258, 0.1264, 0.1256, 0.1282],\n",
      "        [0.1284, 0.1224, 0.1191, 0.1205, 0.1277, 0.1281, 0.1270, 0.1267],\n",
      "        [0.1312, 0.1222, 0.1183, 0.1212, 0.1260, 0.1268, 0.1261, 0.1281],\n",
      "        [0.1249, 0.1281, 0.1220, 0.1239, 0.1256, 0.1265, 0.1243, 0.1247],\n",
      "        [0.1302, 0.1229, 0.1191, 0.1209, 0.1257, 0.1258, 0.1276, 0.1279],\n",
      "        [0.1292, 0.1222, 0.1190, 0.1219, 0.1291, 0.1256, 0.1271, 0.1260],\n",
      "        [0.1304, 0.1217, 0.1183, 0.1212, 0.1277, 0.1273, 0.1268, 0.1266],\n",
      "        [0.1295, 0.1215, 0.1187, 0.1203, 0.1264, 0.1284, 0.1274, 0.1279]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1246, 0.1272, 0.1245, 0.1248, 0.1243, 0.1246, 0.1245, 0.1254],\n",
      "        [0.1253, 0.1261, 0.1239, 0.1250, 0.1260, 0.1244, 0.1259, 0.1234],\n",
      "        [0.1240, 0.1266, 0.1241, 0.1253, 0.1244, 0.1260, 0.1244, 0.1252],\n",
      "        [0.1263, 0.1262, 0.1245, 0.1246, 0.1243, 0.1247, 0.1241, 0.1251],\n",
      "        [0.1259, 0.1242, 0.1212, 0.1244, 0.1263, 0.1262, 0.1258, 0.1258],\n",
      "        [0.1227, 0.1268, 0.1243, 0.1237, 0.1242, 0.1266, 0.1259, 0.1258],\n",
      "        [0.1246, 0.1259, 0.1243, 0.1246, 0.1260, 0.1249, 0.1235, 0.1261],\n",
      "        [0.1254, 0.1256, 0.1222, 0.1251, 0.1236, 0.1281, 0.1241, 0.1259],\n",
      "        [0.1245, 0.1255, 0.1228, 0.1251, 0.1246, 0.1259, 0.1263, 0.1255],\n",
      "        [0.1247, 0.1269, 0.1251, 0.1249, 0.1260, 0.1246, 0.1230, 0.1249],\n",
      "        [0.1247, 0.1253, 0.1244, 0.1246, 0.1250, 0.1254, 0.1247, 0.1259],\n",
      "        [0.1267, 0.1248, 0.1226, 0.1260, 0.1257, 0.1248, 0.1245, 0.1250],\n",
      "        [0.1254, 0.1247, 0.1228, 0.1247, 0.1248, 0.1269, 0.1244, 0.1263],\n",
      "        [0.1259, 0.1253, 0.1238, 0.1257, 0.1262, 0.1225, 0.1243, 0.1263]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "07/10 07:06:53 PM train 000 1.640835e+00 37.500000 87.500000\n",
      "07/10 07:11:13 PM train 050 1.503172e+00 46.017159 91.482849\n",
      "07/10 07:15:33 PM train 100 1.483124e+00 45.451733 91.707916\n",
      "07/10 07:19:59 PM train 150 1.480274e+00 45.633278 91.970200\n",
      "07/10 07:20:32 PM train_acc 45.719997\n",
      "07/10 07:20:33 PM valid 000 1.937138e+00 28.125000 78.125000\n",
      "07/10 07:20:43 PM valid 050 1.483053e+00 46.936275 90.012260\n",
      "07/10 07:20:51 PM valid 100 1.497102e+00 46.256187 90.315590\n",
      "07/10 07:20:59 PM valid 150 1.503281e+00 45.881622 90.749168\n",
      "07/10 07:21:00 PM valid_acc 45.719997\n",
      "07/10 07:21:01 PM valid 000 1.685643e+00 50.000000 84.375000\n",
      "07/10 07:21:09 PM valid 050 1.617598e+00 43.198532 87.438728\n",
      "07/10 07:21:17 PM valid 100 1.617909e+00 42.945545 87.623764\n",
      "07/10 07:21:25 PM valid 150 1.615332e+00 43.232616 87.893211\n",
      "07/10 07:21:26 PM valid_acc1 43.379997\n",
      "07/10 07:21:26 PM valid 000 2.216674e+00 43.750000 78.125000\n",
      "07/10 07:21:34 PM valid 050 1.952810e+00 38.174023 86.887260\n",
      "07/10 07:21:42 PM valid 100 1.969199e+00 37.438118 86.324257\n",
      "07/10 07:21:50 PM valid 150 1.960203e+00 37.996689 86.258278\n",
      "07/10 07:21:50 PM valid_acc2 37.939999\n",
      "07/10 07:21:51 PM valid 000 1.544684e+00 43.750000 90.625000\n",
      "07/10 07:21:59 PM valid 050 1.737158e+00 41.360294 88.480392\n",
      "07/10 07:22:06 PM valid 100 1.703839e+00 42.017326 89.542076\n",
      "07/10 07:22:14 PM valid 150 1.710135e+00 41.535595 88.969368\n",
      "07/10 07:22:15 PM valid_acc3 41.619999\n",
      "07/10 07:22:16 PM valid 000 1.601022e+00 40.625000 90.625000\n",
      "07/10 07:22:25 PM valid 050 1.545380e+00 44.301472 89.644608\n",
      "07/10 07:22:34 PM valid 100 1.552690e+00 43.471535 90.470299\n",
      "07/10 07:22:44 PM valid 150 1.540362e+00 44.246689 90.976822\n",
      "07/10 07:22:45 PM valid_acc4 44.200001\n",
      "07/10 07:22:45 PM epoch 4 lr 2.420423e-02\n",
      "07/10 07:22:45 PM genotype = Genotype(normal=[('max_pool_3x3', 0), ('sep_conv_3x3', 1), ('max_pool_3x3', 0), ('dil_conv_5x5', 1), ('sep_conv_5x5', 2), ('max_pool_3x3', 0), ('sep_conv_3x3', 2), ('sep_conv_5x5', 4)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('sep_conv_3x3', 1), ('max_pool_3x3', 0), ('dil_conv_5x5', 2), ('sep_conv_5x5', 2), ('max_pool_3x3', 0), ('sep_conv_5x5', 3), ('max_pool_3x3', 0)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1225, 0.1295, 0.1204, 0.1242, 0.1272, 0.1268, 0.1246, 0.1249],\n",
      "        [0.1313, 0.1233, 0.1187, 0.1212, 0.1267, 0.1266, 0.1256, 0.1266],\n",
      "        [0.1236, 0.1296, 0.1208, 0.1244, 0.1242, 0.1253, 0.1277, 0.1243],\n",
      "        [0.1307, 0.1235, 0.1186, 0.1216, 0.1234, 0.1254, 0.1281, 0.1287],\n",
      "        [0.1299, 0.1227, 0.1180, 0.1236, 0.1249, 0.1267, 0.1265, 0.1279],\n",
      "        [0.1260, 0.1288, 0.1196, 0.1225, 0.1244, 0.1271, 0.1257, 0.1259],\n",
      "        [0.1324, 0.1228, 0.1185, 0.1208, 0.1262, 0.1255, 0.1262, 0.1275],\n",
      "        [0.1295, 0.1220, 0.1176, 0.1199, 0.1279, 0.1293, 0.1262, 0.1276],\n",
      "        [0.1328, 0.1210, 0.1162, 0.1194, 0.1263, 0.1286, 0.1272, 0.1286],\n",
      "        [0.1248, 0.1294, 0.1212, 0.1238, 0.1254, 0.1267, 0.1240, 0.1246],\n",
      "        [0.1318, 0.1225, 0.1179, 0.1203, 0.1247, 0.1259, 0.1280, 0.1290],\n",
      "        [0.1303, 0.1218, 0.1174, 0.1216, 0.1299, 0.1251, 0.1277, 0.1262],\n",
      "        [0.1327, 0.1207, 0.1165, 0.1202, 0.1278, 0.1287, 0.1266, 0.1269],\n",
      "        [0.1309, 0.1204, 0.1167, 0.1188, 0.1269, 0.1297, 0.1280, 0.1286]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1245, 0.1281, 0.1245, 0.1246, 0.1245, 0.1239, 0.1250, 0.1249],\n",
      "        [0.1258, 0.1261, 0.1236, 0.1250, 0.1268, 0.1248, 0.1250, 0.1228],\n",
      "        [0.1233, 0.1278, 0.1246, 0.1263, 0.1241, 0.1243, 0.1244, 0.1251],\n",
      "        [0.1273, 0.1266, 0.1248, 0.1237, 0.1238, 0.1261, 0.1234, 0.1244],\n",
      "        [0.1252, 0.1241, 0.1199, 0.1239, 0.1270, 0.1267, 0.1260, 0.1271],\n",
      "        [0.1221, 0.1280, 0.1248, 0.1239, 0.1245, 0.1263, 0.1247, 0.1257],\n",
      "        [0.1252, 0.1261, 0.1245, 0.1248, 0.1260, 0.1250, 0.1228, 0.1256],\n",
      "        [0.1247, 0.1262, 0.1214, 0.1253, 0.1231, 0.1284, 0.1243, 0.1267],\n",
      "        [0.1246, 0.1259, 0.1224, 0.1259, 0.1243, 0.1251, 0.1265, 0.1253],\n",
      "        [0.1241, 0.1278, 0.1253, 0.1249, 0.1252, 0.1250, 0.1231, 0.1246],\n",
      "        [0.1246, 0.1253, 0.1245, 0.1246, 0.1259, 0.1251, 0.1243, 0.1258],\n",
      "        [0.1270, 0.1248, 0.1212, 0.1259, 0.1270, 0.1240, 0.1245, 0.1256],\n",
      "        [0.1257, 0.1241, 0.1217, 0.1250, 0.1253, 0.1281, 0.1234, 0.1268],\n",
      "        [0.1269, 0.1246, 0.1220, 0.1249, 0.1271, 0.1232, 0.1244, 0.1268]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/10 07:22:51 PM train 000 1.366883e+00 43.750000 90.625000\n",
      "07/10 07:27:13 PM train 050 1.427678e+00 47.855392 92.524513\n",
      "07/10 07:31:42 PM train 100 1.393295e+00 49.071781 92.698021\n",
      "07/10 07:36:05 PM train 150 1.387664e+00 48.820366 93.046356\n",
      "07/10 07:36:36 PM train_acc 48.639999\n",
      "07/10 07:36:37 PM valid 000 1.661203e+00 43.750000 87.500000\n",
      "07/10 07:36:45 PM valid 050 1.523232e+00 44.240196 90.808830\n",
      "07/10 07:36:53 PM valid 100 1.530440e+00 44.863861 90.594055\n",
      "07/10 07:37:01 PM valid 150 1.515133e+00 45.509106 91.142387\n",
      "07/10 07:37:02 PM valid_acc 48.639999\n",
      "07/10 07:37:02 PM valid 000 1.743926e+00 37.500000 78.125000\n",
      "07/10 07:37:10 PM valid 050 1.765729e+00 35.416668 85.232849\n",
      "07/10 07:37:18 PM valid 100 1.763617e+00 35.365097 84.746284\n",
      "07/10 07:37:26 PM valid 150 1.773552e+00 35.264900 84.768211\n",
      "07/10 07:37:27 PM valid_acc1 35.299999\n",
      "07/10 07:37:27 PM valid 000 1.246560e+00 56.250000 96.875000\n",
      "07/10 07:37:36 PM valid 050 1.497644e+00 48.345589 92.892159\n",
      "07/10 07:37:46 PM valid 100 1.524849e+00 46.998760 92.017326\n",
      "07/10 07:37:55 PM valid 150 1.528531e+00 46.916389 91.825333\n",
      "07/10 07:37:56 PM valid_acc2 47.119999\n",
      "07/10 07:37:56 PM valid 000 1.784264e+00 37.500000 93.750000\n",
      "07/10 07:38:04 PM valid 050 1.631765e+00 42.892159 90.870102\n",
      "07/10 07:38:14 PM valid 100 1.569144e+00 44.894802 91.336632\n",
      "07/10 07:38:24 PM valid 150 1.574941e+00 45.343544 91.411423\n",
      "07/10 07:38:25 PM valid_acc3 45.259998\n",
      "07/10 07:38:25 PM valid 000 1.809516e+00 28.125000 90.625000\n",
      "07/10 07:38:35 PM valid 050 1.600728e+00 41.973042 90.441177\n",
      "07/10 07:38:45 PM valid 100 1.591791e+00 42.419556 90.191833\n",
      "07/10 07:38:54 PM valid 150 1.585747e+00 42.508278 90.438744\n",
      "07/10 07:38:56 PM valid_acc4 42.419998\n",
      "07/10 07:38:56 PM epoch 5 lr 2.390474e-02\n",
      "07/10 07:38:56 PM genotype = Genotype(normal=[('max_pool_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_5x5', 2), ('max_pool_3x3', 0), ('dil_conv_5x5', 3), ('sep_conv_5x5', 2), ('sep_conv_5x5', 4), ('sep_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('sep_conv_3x3', 1), ('sep_conv_5x5', 2), ('max_pool_3x3', 0), ('sep_conv_5x5', 2), ('max_pool_3x3', 0), ('sep_conv_5x5', 3), ('sep_conv_3x3', 2)], reduce_concat=range(2, 6))\n",
      "tensor([[0.1227, 0.1292, 0.1189, 0.1237, 0.1270, 0.1279, 0.1251, 0.1255],\n",
      "        [0.1320, 0.1215, 0.1168, 0.1200, 0.1268, 0.1280, 0.1268, 0.1280],\n",
      "        [0.1240, 0.1292, 0.1192, 0.1238, 0.1246, 0.1254, 0.1287, 0.1250],\n",
      "        [0.1327, 0.1220, 0.1172, 0.1211, 0.1239, 0.1255, 0.1286, 0.1291],\n",
      "        [0.1318, 0.1210, 0.1155, 0.1225, 0.1247, 0.1271, 0.1273, 0.1301],\n",
      "        [0.1267, 0.1286, 0.1181, 0.1219, 0.1253, 0.1277, 0.1257, 0.1260],\n",
      "        [0.1348, 0.1212, 0.1167, 0.1198, 0.1259, 0.1267, 0.1269, 0.1280],\n",
      "        [0.1308, 0.1205, 0.1149, 0.1179, 0.1290, 0.1305, 0.1273, 0.1291],\n",
      "        [0.1348, 0.1192, 0.1134, 0.1170, 0.1271, 0.1299, 0.1275, 0.1310],\n",
      "        [0.1257, 0.1292, 0.1200, 0.1235, 0.1249, 0.1274, 0.1237, 0.1256],\n",
      "        [0.1338, 0.1210, 0.1162, 0.1192, 0.1252, 0.1264, 0.1292, 0.1291],\n",
      "        [0.1319, 0.1202, 0.1146, 0.1197, 0.1306, 0.1252, 0.1295, 0.1283],\n",
      "        [0.1356, 0.1192, 0.1139, 0.1184, 0.1282, 0.1298, 0.1274, 0.1275],\n",
      "        [0.1325, 0.1182, 0.1137, 0.1165, 0.1282, 0.1309, 0.1296, 0.1303]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1238, 0.1284, 0.1244, 0.1237, 0.1245, 0.1243, 0.1255, 0.1253],\n",
      "        [0.1265, 0.1248, 0.1224, 0.1252, 0.1277, 0.1253, 0.1250, 0.1230],\n",
      "        [0.1223, 0.1284, 0.1248, 0.1262, 0.1244, 0.1243, 0.1244, 0.1252],\n",
      "        [0.1279, 0.1254, 0.1239, 0.1232, 0.1237, 0.1272, 0.1244, 0.1242],\n",
      "        [0.1250, 0.1233, 0.1187, 0.1239, 0.1277, 0.1284, 0.1258, 0.1272],\n",
      "        [0.1209, 0.1289, 0.1253, 0.1236, 0.1248, 0.1262, 0.1244, 0.1260],\n",
      "        [0.1260, 0.1248, 0.1233, 0.1244, 0.1261, 0.1259, 0.1234, 0.1261],\n",
      "        [0.1245, 0.1257, 0.1205, 0.1257, 0.1228, 0.1297, 0.1245, 0.1265],\n",
      "        [0.1253, 0.1254, 0.1213, 0.1265, 0.1237, 0.1254, 0.1263, 0.1261],\n",
      "        [0.1240, 0.1282, 0.1254, 0.1254, 0.1251, 0.1248, 0.1222, 0.1248],\n",
      "        [0.1245, 0.1245, 0.1238, 0.1248, 0.1250, 0.1253, 0.1250, 0.1271],\n",
      "        [0.1272, 0.1242, 0.1201, 0.1263, 0.1283, 0.1243, 0.1245, 0.1252],\n",
      "        [0.1265, 0.1231, 0.1201, 0.1253, 0.1267, 0.1289, 0.1232, 0.1263],\n",
      "        [0.1274, 0.1233, 0.1206, 0.1250, 0.1272, 0.1240, 0.1250, 0.1276]],\n",
      "       device='cuda:1', grad_fn=<SoftmaxBackward>)\n",
      "07/10 07:39:01 PM train 000 1.463753e+00 50.000000 93.750000\n",
      "07/10 07:43:23 PM train 050 1.338548e+00 51.470589 93.750000\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logging.info('no gpu device available')\n",
    "    sys.exit(1)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "logging.info('gpu device = %d' % args.gpu)\n",
    "logging.info(\"args = %s\", args)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "model = Network(args.init_channels, CIFAR_CLASSES, args.layers, criterion)\n",
    "model = model.cuda()\n",
    "logging.info(\"param size = %fMB\", utils.count_parameters_in_MB(model))\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    args.learning_rate,\n",
    "    momentum=args.momentum,\n",
    "    weight_decay=args.weight_decay)\n",
    "\n",
    "train_transform, valid_transform = utils._data_transforms_cifar10(args)\n",
    "train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(args.train_portion * num_train)*0.2)\n",
    "split_end = int(num_train*0.2)\n",
    "\n",
    "train_queue = torch.utils.data.DataLoader(\n",
    "      train_data, batch_size=args.batch_size,\n",
    "      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
    "      pin_memory=True, num_workers=2)\n",
    "\n",
    "valid_queue = torch.utils.data.DataLoader(\n",
    "      train_data, batch_size=args.batch_size,\n",
    "      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:split_end]),\n",
    "      pin_memory=True, num_workers=2)\n",
    "\n",
    "test_data = dset.CIFAR10(root=args.data, train=False, download=True, transform=valid_transform)\n",
    "\n",
    "test_queue = torch.utils.data.DataLoader(\n",
    "      test_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "      optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "architect = Architect(model, args)\n",
    "\n",
    "\n",
    "arch_archive=[]\n",
    "arch_gen1=random_arch_generate()\n",
    "arch_gen2=random_arch_generate()\n",
    "#arch_gen_compa=[arch_gen_compa1,arch_gen_compa2]\n",
    "#arch_gen_compa=[[(0,0),(7,1),(0,0),(6,1),(0,0),(7,3),(3,1),(5,4)],[(5,0),(7,1),(6,0),(4,0),(3,0),(7,1),(2,4),(4,2)]]\n",
    "#logging.info('arch_gen_compa %f', arch_gen_compa)\n",
    "\n",
    "#arch_gen_compa=[[(0, 0), (0, 1), (7, 1), (7, 2), (6, 3), (4, 0), (2, 3), (6, 4)], [(7, 0), (4, 1), (4, 2), (2, 1), (1, 0), (5, 1), (4, 0), (4, 2)]]\n",
    "\n",
    "arch_gen_compa1 = [[(0, 0), (7, 1), (0, 0), (6, 1), (0, 0), (7, 3), (3, 1), (5, 4)], [(5, 0), (7, 1), (6, 0), (4, 1), (3, 0), (7, 1), (2, 4), (4, 2)]]\n",
    "arch_gen_compa2 = [[(6, 0), (6, 1), (3, 1), (1, 0), (4, 1), (6, 3), (2, 4), (7, 0)], [(2, 1), (5, 0), (7, 2), (1, 0), (7, 1), (1, 3), (5, 3), (1, 0)]]\n",
    "arch_gen_compa3 = [[(2, 0), (6, 1), (0, 1), (3, 2), (2, 1), (0, 3), (0, 0), (2, 3)], [(6, 1), (6, 0), (3, 0), (0, 1), (4, 2), (0, 0), (1, 4), (5, 3)]]\n",
    "arch_gen_compa4 = [[(7, 0), (6, 1), (4, 1), (5, 0), (2, 1), (3, 2), (5, 2), (7, 0)], [(0, 1), (6, 0), (5, 0), (3, 2), (6, 3), (5, 1), (6, 3), (3, 4)]]\n",
    "\n",
    "\n",
    "n_archive_recent=[arch_gen1]\n",
    "r_archive_recent=[arch_gen2]\n",
    "\n",
    "record_train_acc=[]\n",
    "record_valid_acc=[]\n",
    "record_valid_accs=[]\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    logging.info('epoch %d lr %e', epoch, lr)\n",
    "\n",
    "    genotype = model.genotype()\n",
    "    logging.info('genotype = %s', genotype)\n",
    "\n",
    "    print(F.softmax(model.alphas_normal, dim=-1))\n",
    "    print(F.softmax(model.alphas_reduce, dim=-1))\n",
    "\n",
    "    # training\n",
    "    train_acc, train_obj= train(train_queue, valid_queue, model, architect, criterion, optimizer, lr)\n",
    "    logging.info('train_acc %f', train_acc)\n",
    "\n",
    "    # validation    \n",
    "    valid_acc, valid_obj = infer(valid_queue, model, criterion)\n",
    "    logging.info('valid_acc %f', train_acc)        \n",
    "    \n",
    "\n",
    "    # validation seperate architecture\n",
    "    valid_acc1, valid_obj = infer_val(valid_queue, model,arch_gen_compa1, criterion)\n",
    "    logging.info('valid_acc1 %f', valid_acc1)\n",
    "    \n",
    "    \n",
    "    valid_acc2, valid_obj = infer_val(valid_queue, model,arch_gen_compa2, criterion)\n",
    "    logging.info('valid_acc2 %f', valid_acc2) \n",
    "    \n",
    "    valid_acc3, valid_obj = infer_val(valid_queue, model,arch_gen_compa3, criterion)\n",
    "    logging.info('valid_acc3 %f', valid_acc3)\n",
    "    \n",
    "    valid_acc4, valid_obj = infer_val(valid_queue, model,arch_gen_compa4, criterion)\n",
    "    logging.info('valid_acc4 %f', valid_acc4)\n",
    "    \n",
    "    \n",
    "    record_train_acc.extend([train_acc])\n",
    "    record_valid_acc.extend([[valid_acc]])\n",
    "    record_valid_accs.extend([[valid_acc1,valid_acc2,valid_acc3,valid_acc4]])\n",
    "    \n",
    "    \n",
    "file=open('record_train_acc_DARTS.txt','w')    \n",
    "file.write(str(record_train_acc))\n",
    "file.close()\n",
    "                             \n",
    "file=open('record_valid_accs_DARTS.txt','w')    \n",
    "file.write(str(record_valid_accs))\n",
    "file.close()                             \n",
    "                             \n",
    "file=open('record_valid_acc_DARTS.txt','w')    \n",
    "file.write(str(record_valid_acc))\n",
    "file.close()                             \n",
    "\n",
    "   # utils.save(model, os.path.join(args.save, 'weights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc1, valid_obj = infer_val(valid_queue, model,arch_gen_compa1, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
